{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYTHONUTF8=1\n",
      "env: JAVA_HOME=C:\\\\Program Files\\\\Java\\\\jdk-14.0.2\n"
     ]
    }
   ],
   "source": [
    "%env PYTHONUTF8 1\n",
    "%env JAVA_HOME C:\\\\Program Files\\\\Java\\\\jdk-14.0.2\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T10:13:08.503614200Z",
     "start_time": "2025-03-18T10:13:08.495094400Z"
    }
   },
   "id": "eb04d9c98cbce890",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-18T10:13:31.437037700Z",
     "start_time": "2025-03-18T10:13:31.427014200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/bm25_top_100_claimdecomp.json')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T10:02:10.518915100Z",
     "start_time": "2025-03-18T10:02:08.700797300Z"
    }
   },
   "id": "e1469f51fc3aadf8",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                              doc_id  \\\n0  [318105, 103145, 286450, 36740, 108519, 334876...   \n1  [355804, 391541, 379773, 247608, 144123, 30351...   \n2  [224154, 372689, 163700, 378592, 279362, 34357...   \n3  [121666, 108452, 319786, 302265, 211057, 25646...   \n4  [78775, 85626, 83120, 39424, 276685, 55567, 31...   \n\n                                              scores  query_id  \\\n0  [62.99001, 61.76746, 59.64837, 48.942146, 42.2...         0   \n1  [69.345276, 65.04173, 63.49755, 60.157364, 46....         1   \n2  [44.3021, 41.267403, 39.704765, 39.443134, 38....         2   \n3  [49.45101, 44.59274, 43.89805, 43.21086, 42.54...         3   \n4  [44.742607, 44.36633, 43.22013, 40.117928, 39....         4   \n\n                                               claim  \\\n0  \"The non-partisan Congressional Budget Office ...   \n1  \"More than 50 percent of immigrants from (El S...   \n2  UK government banned Covid vaccine for childre...   \n3  \"[In 2014-2015] coverage for the rotavirus vac...   \n4  In September 2021, the U.K. government announc...   \n\n                                                docs  \n0  [7 gen 2022  the nonpartisan congressional bud...  \n1  [percent of persons using at least one prescri...  \n2  [5 oct. 2023  primary course vaccination is re...  \n3  [the immunization coverage targets (at least 9...  \n4  [17 juin 2022  in 2019, kentucky ranked ninth ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>doc_id</th>\n      <th>scores</th>\n      <th>query_id</th>\n      <th>claim</th>\n      <th>docs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[318105, 103145, 286450, 36740, 108519, 334876...</td>\n      <td>[62.99001, 61.76746, 59.64837, 48.942146, 42.2...</td>\n      <td>0</td>\n      <td>\"The non-partisan Congressional Budget Office ...</td>\n      <td>[7 gen 2022  the nonpartisan congressional bud...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[355804, 391541, 379773, 247608, 144123, 30351...</td>\n      <td>[69.345276, 65.04173, 63.49755, 60.157364, 46....</td>\n      <td>1</td>\n      <td>\"More than 50 percent of immigrants from (El S...</td>\n      <td>[percent of persons using at least one prescri...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[224154, 372689, 163700, 378592, 279362, 34357...</td>\n      <td>[44.3021, 41.267403, 39.704765, 39.443134, 38....</td>\n      <td>2</td>\n      <td>UK government banned Covid vaccine for childre...</td>\n      <td>[5 oct. 2023  primary course vaccination is re...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[121666, 108452, 319786, 302265, 211057, 25646...</td>\n      <td>[49.45101, 44.59274, 43.89805, 43.21086, 42.54...</td>\n      <td>3</td>\n      <td>\"[In 2014-2015] coverage for the rotavirus vac...</td>\n      <td>[the immunization coverage targets (at least 9...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[78775, 85626, 83120, 39424, 276685, 55567, 31...</td>\n      <td>[44.742607, 44.36633, 43.22013, 40.117928, 39....</td>\n      <td>4</td>\n      <td>In September 2021, the U.K. government announc...</td>\n      <td>[17 juin 2022  in 2019, kentucky ranked ninth ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T10:02:12.615141800Z",
     "start_time": "2025-03-18T10:02:12.586957100Z"
    }
   },
   "id": "957b764f49f6e651",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open('../data/corpus_evidence_unified.json', 'r') as file:\n",
    "    data = json.load(file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c95512bfee3856c2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "# Print the loaded data\n",
    "print(data[\"0\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd14ddfa98d5ce15",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "765277bb18f3c169",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = pt.get_dataset('irds:c4/en-noclean-tr/trec-misinfo-2021')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "634696d51b3259ae",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] [starting] https://ai2-s2-research-public.s3-us-west-2.amazonaws.com/ir-datasets/c4/en.noclean.sources.json.gz\n",
      "[INFO] [finished] https://ai2-s2-research-public.s3-us-west-2.amazonaws.com/ir-datasets/c4/en.noclean.sources.json.gz: [00:00] [241kB] [427kB/s]\n",
      "[INFO] Will start downloading c4/en-noclean files (2.4TB). If you already have a copy, you may link them to C:\\Users\\skakr\\.ir_datasets\\c4\\en.noclean (should contain files like c4-train.00000-of-07168.json.gz)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Insufficient disk space: C:\\Users\\skakr\\.ir_datasets\\c4\\en.noclean requires 2.4TB but only 33.7GB is available (2.4TB more needed)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_corpus_iter\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\Documents\\Programming\\ms-information-retrieval\\.venv\\Lib\\site-packages\\pyterrier\\datasets.py:414\u001B[0m, in \u001B[0;36mIRDSDataset.get_corpus_iter\u001B[1;34m(self, verbose, start, count)\u001B[0m\n\u001B[0;32m    412\u001B[0m ds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mirds_ref()\n\u001B[0;32m    413\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m ds\u001B[38;5;241m.\u001B[39mhas_docs(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_irds_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt support get_corpus_iter\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 414\u001B[0m it \u001B[38;5;241m=\u001B[39m \u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdocs_iter\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    415\u001B[0m total \u001B[38;5;241m=\u001B[39m ds\u001B[38;5;241m.\u001B[39mdocs_count()\n\u001B[0;32m    417\u001B[0m \u001B[38;5;66;03m# use slicing if requested\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Programming\\ms-information-retrieval\\.venv\\Lib\\site-packages\\ir_datasets\\datasets\\c4.py:155\u001B[0m, in \u001B[0;36mC4Docs.docs_iter\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdocs_iter\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m--> 155\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m SourceDocIter(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mslice\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdocs_count\u001B[49m\u001B[43m(\u001B[49m\u001B[43mforce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m))\n",
      "File \u001B[1;32m~\\Documents\\Programming\\ms-information-retrieval\\.venv\\Lib\\site-packages\\ir_datasets\\datasets\\c4.py:166\u001B[0m, in \u001B[0;36mC4Docs.docs_count\u001B[1;34m(self, force)\u001B[0m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdocs_count\u001B[39m(\u001B[38;5;28mself\u001B[39m, force\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sources \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 166\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msum\u001B[39m(s\u001B[38;5;241m.\u001B[39mdoc_count \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_docs_sources\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\Documents\\Programming\\ms-information-retrieval\\.venv\\Lib\\site-packages\\ir_datasets\\datasets\\c4.py:196\u001B[0m, in \u001B[0;36mC4Docs._docs_sources\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m remaining_size \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    193\u001B[0m     _logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWill start downloading c4/en-noclean files (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mir_datasets\u001B[38;5;241m.\u001B[39mutil\u001B[38;5;241m.\u001B[39mformat_file_size(remaining_size)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m). \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    194\u001B[0m                  \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIf you already have a copy, you may link them to \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_base_path\u001B[38;5;250m \u001B[39m\u001B[38;5;241m/\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124men.noclean\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (should contain \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    195\u001B[0m                  \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfiles like c4-train.00000-of-07168.json.gz)\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 196\u001B[0m     \u001B[43mir_datasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_disk_free\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_base_path\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43men.noclean\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mremaining_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    197\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m source \u001B[38;5;129;01min\u001B[39;00m sources:\n\u001B[0;32m    198\u001B[0m     path \u001B[38;5;241m=\u001B[39m source\u001B[38;5;241m.\u001B[39mdlc\u001B[38;5;241m.\u001B[39mpath() \u001B[38;5;66;03m# downloads if it doesn't already exist\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\Programming\\ms-information-retrieval\\.venv\\Lib\\site-packages\\ir_datasets\\util\\__init__.py:234\u001B[0m, in \u001B[0;36mcheck_disk_free\u001B[1;34m(target_path, required_size, message)\u001B[0m\n\u001B[0;32m    232\u001B[0m required_size_fmt \u001B[38;5;241m=\u001B[39m format_file_size(required_size)\n\u001B[0;32m    233\u001B[0m free_size_fmt \u001B[38;5;241m=\u001B[39m format_file_size(free_size)\n\u001B[1;32m--> 234\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(message\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m    235\u001B[0m     target_path\u001B[38;5;241m=\u001B[39mtarget_path,\n\u001B[0;32m    236\u001B[0m     required_size\u001B[38;5;241m=\u001B[39mrequired_size,\n\u001B[0;32m    237\u001B[0m     required_size_fmt\u001B[38;5;241m=\u001B[39mrequired_size_fmt,\n\u001B[0;32m    238\u001B[0m     missing_size\u001B[38;5;241m=\u001B[39mmissing_size,\n\u001B[0;32m    239\u001B[0m     missing_size_fmt\u001B[38;5;241m=\u001B[39mmissing_size_fmt,\n\u001B[0;32m    240\u001B[0m     free_size\u001B[38;5;241m=\u001B[39mfree_size,\n\u001B[0;32m    241\u001B[0m     free_size_fmt\u001B[38;5;241m=\u001B[39mfree_size_fmt))\n",
      "\u001B[1;31mValueError\u001B[0m: Insufficient disk space: C:\\Users\\skakr\\.ir_datasets\\c4\\en.noclean requires 2.4TB but only 33.7GB is available (2.4TB more needed)"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset.get_corpus_iter()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-18T10:14:02.637692300Z",
     "start_time": "2025-03-18T10:14:00.811018600Z"
    }
   },
   "id": "1db4fb9f0fdb5413",
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
